Question 1: How is the communication between the host and the graphic card handled?

Through buffers and command queues.

Buffers are created and passed to the function that launches the kernel.

command queues are associated with a context (a collection of devices that talks opencl) and a list of devices in that context.

Question 2: What function executes your kernel?
clEnqueueNDRangeKernel

Question 3: How does the kernel know what element to work on?

Through:
size_t get_global_id(uint dimindx); // work_item id

// Global ids
unsigned int global_x = get_global_id(0);

QUESTION 4: How much data did you put in local (shared memory?

(BLOCK_DIM+2*KERNELSIZE)*(BLOCK_DIM+2*KERNELSIZE)*PIXEL_SIZE
If filter size is 5x5 then KERNELSIZE is 2, this means I will in all directions look 2 pixels out from the current pixel in order to filter the current pixel.

QUESTION 5: How much data does each thread copy to local memory?

4 pixels, a pixel is 3x8bit -> 12 bytes
*---*
--x--  where x is the pixel to be filtered by the current thread.
*---*

QUESTION 6: How did you handle the necessary overlap between the work groups?

index depend on the local id i.e. 
get_local_id(0) = x % image width
get_local_id(1) = y % image height

*---*
--x--  where x is the pixel to be filtered by the current thread.
*---*

Each local thread loads those four pixels.

QUESTION 7: If we would like to increase the block size, about how big work groups would be safe to use in this case? Why?

Number of cores in our SM is: 1024
This means we have a maximum block dimension of: 32*32

Memory usage for a X*X work group is:
PIXEL_SIZE*(X+2*KERNELSIZE)^2 bytes

As long as this fits in the SMs memory it is safe, else we need to decrease the work group dimension.

QUESTION 8: How much speedup did you get over the naive version?

~22%
